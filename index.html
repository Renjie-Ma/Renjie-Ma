<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Meta-learning for Bridging Labeled and Unlabeled Data in Biomedicine</title>

<!-- Standard reset, fonts and grids -->
<link rel="stylesheet" type="text/css" href="reset-fonts-grids.css">
<!-- styles for the whole website -->
<link href="styles.css" rel="stylesheet" type="text/css" />
</head>  
   
<body class="yui-skin-sam" id="yahoo-com">
<div id="doc" class="yui-t1">
<div id="hd">
</div>

<!-- START: left column -->
<div id="left-column">
<br><br>
  <!--BEGIN left_column.html -->
  <center><a href="index.html"><img id="snap-logo" src="http://snap.stanford.edu/images/seal.gif" alt="Stanford"/></a></center>
  <ul id="links-under-menu">
  <li><a href="index.html#motivation">Motivation</a></li>
  <li><a href="index.html#objectives">Objectives</a></li>
  <li><a href="index.html#outline">Outline</a></li>
  <li><a href="index.html#info">Info</a></li>
  <li><a href="index.html#organizers">Presenters</a></li>
  </ul> 
  <!--END left_column.html -->
</div>
<!-- END: left column -->

<!-- START: right column -->
<div id="right-column">

<br>

<br>

<br>
<br>
<div style="color:#ff8b00; font-size:28px; font-weight:bold;"><a href="https://www.iscb.org/ismbeccb2021-program/tutorials#tut1">ISMB/ECCB 2021 Tutorial</a></div><br>
<div style="color:#ff8b00; font-size:36px; font-weight:bold;">Meta-learning for Bridging Labeled and Unlabeled Data in Biomedicine</div>

<div class="call-out-green">
<p>
This tutorial will cover principles and recent advancements of meta-learning with the case studies designed based on their high relevance for advancing new biomedical discoveries. We will present representation learning methods that bridge labeled and unlabeled data by learning to generalize across datasets given only a few labeled examples or extremely without any labeled data. 
</p>
</div>
<a href="meta_ismb.png"><img src="img/meta_ismb.png" width="700" style="display: block; margin: 0 auto;"></img><br /></a>

<A name="motivation"></A>
<h2>Tutorial goals</h2>

<p>
In biomedical domains labeled datasets are often very difficult and time-consuming to obtain, requiring a lot of costly manual effort and expert knowledge to hand-label classes before machine learning methods can even be used. This results in many scarcely labeled or completely unlabeled datasets. For instance, in protein function prediction a large number of functional labels have only a few labeled genes, or in single-cell transcriptomics novel and rare cell types appear across large, heterogeneous single-cell datasets. </p>

<p>
While machine learning methods excel on tasks with a large number of labeled datasets that can support learning of highly parameterized models, to solve central problems in biomedicine we need methods that can generalize to unseen domains and datasets given only a few labeled training examples, or in the extreme case to completely unlabeled datasets. Major advances under low-data regime tasks have been achieved by leveraging knowledge across related tasks with meta-learning, or learning to learn across tasks. The central idea behind meta-learning is to acquire prior knowledge over previous tasks so that new tasks can be efficiently learned from a small amount of data. </p>

<p>
This tutorial will cover principles and recent advancements of meta-learning with the case studies designed based on their high relevance for advancing new biomedical discoveries. We will present representation learning methods that bridge labeled and unlabeled data by learning to generalize across datasets given only a few labeled examples or extremely without any labeled data with an emphasis on interpretability. We will spend considerable amount of time to explain how can interpretability be incorporated as an essential feature in the design of the methods. The tutorial will equip participants with the ability to understand fundamentals and state-of-the-art meta-learning methods and to utilize the learned concepts and methods in their own research.
</p>

<A name="objectives"></A>
<h2>Learning objectives</h2>

<p>
At the completion of the tutorial, the participants will gain understanding and broad knowledge about the basic concepts and recent advances in the meta-learning techniques:
<ul>
  <li> How can we effectively learn from scarcely labeled datasets, <i>e.g.</i>, protein functions or structures with a few labeled examples? How can we use prior knowledge to learn to generalize, <i>i.e.</i>, meta-learn?</li>
  <li> How can we utilize knowledge from existing knowledge bases, such as Gene Ontology and Cell Ontology, to provide interpretations behind decisions based on only few-labeled examples?</li>
  <li> How can we learn without <i>any</i> labeled examples? How can we discover new, never-before-seen categories/classes, such as rare and unseen cell types across single-cell experiments?</li>
  <li> How can we transfer knowledge across different species, tissues, or sequencing technologies?</li>
  <li> What fundamental open problems in biology can benefit from meta-learning techniques? How can meta-learning be applied to these problems?</li>
  <li> What frameworks, tools and libraries are available to use meta-learning methods on new datasets and applications?   </li>
</ul>
</p>


<A name="outline"></A>
<h2>Tutorial materials and outline</h2>

<p>
Our tutorial will cover fundamental techniques and recent advances on machine learning methods that have an ability to generalize from a small number of labels, or in the extreme case without any labels. The participants will acquire knowledge of fundamental concepts and understanding how to use these methods to advance new discoveries in their own research. 
</p>

<p>
Tutorial will be organised as a half-day tutorial. Tutorial materials will be posted on this website in early July 2021. 
</p>

<p>
Detailed outline of the tutorial is the following:
</p>
<p>
<ul>
  <li style="font-weight:bold;">Introduction <a href="materials/intro.pdf">[slides]</a> </li>
    <ul>
    <li> Types of missing data problems</li>
    <li> Basics of deep learning</li>
    </ul>
  <li style="font-weight:bold;">Few-shot learning part I: Meta-learning for few-shot learning  <a href="materials/fewshot-metalearning.pdf">[slides]</a></li>
    <ul>
    <li> Problem statement: Few-shot learning</li>
    <li> Optimization-based methods (e.g., <a href="https://arxiv.org/pdf/1703.03400.pdf">MAML</a>)</li>
    <li> Metric-based methods (e.g., <a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf">Siamese</a>, <a href="https://arxiv.org/pdf/1606.04080.pdf">MatchingNet</a>, <a href="https://arxiv.org/pdf/1703.05175.pdf">ProtoNet</a>)</li>
    <li> <i>Applications:</i> Drug discovery and cellular response prediction </li>
    </ul>
  <li style="font-weight:bold;">Few-shot learning part II: Integrating side information  <a href="materials/fewshot-prior-knowledge.pdf">[slides]</a></li>
    <ul>
    <li> Feature level prior knowledge for interpretability (e.g. <a href="https://arxiv.org/pdf/2007.07375.pdf">COMET</a>)</li>
   	<li> Class level prior knowledge (e.g., <a href="https://arxiv.org/pdf/1902.07104.pdf">AM3</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3394486.3403230">TAdaNet</a>)</li>
    <li> <i>Applications:</i> Interpretable cell type annotation, disease prediction </li>
    </ul>
  <li style="font-weight:bold;">Open-world learning  <a href="materials/open-world-learning.pdf">[slides]</a></li>
    <ul>
    <li> Problem statement: Open-world learning </li>
    <li> Novel class discovery (e.g., <a href="https://www.nature.com/articles/s41592-020-00979-3">MARS</a>)
    <li> Open-world semi-supervised learning (e.g., <a href="https://arxiv.org/pdf/2102.03526.pdf">ORCA</a>)
    <li> <i>Applications:</i> Cell type discovery from single-cell data and multiplexed imaging technology CODEX
    </ul>
  <li style="font-weight:bold;">Guidelines and conclusions  <a href="materials/conclusion.pdf">[slides]</a></li>
  	<ul>
    <li> Tips and guidelines on available resources, libraries and tools</li>
    <li> Demo on prototypical networks for cell type annotation  <a href="materials/prototypical-single-cell.ipynb">[ipynb]</a> </li>
    <li> Future perspectives and concluding remarks</li>
    </ul>
</ul>
</p>

<A name="info"></A>
<h2>Tutorial info</h2>

<!-- <h3>Location</h3> -->

<!-- <p> Tutorial will be held at <a href="https://www.iscb.org/ismb2018">ISMB conference</a> (<a href="https://www.iscb.org/ismb2018-program/ismb2018-tutorials">Grand Ballroom A</a>) in Chicago, IL on Friday, July 6 2018.</p>

<p>Tutorial will start at 2:00 pm and go until 6:00 pm with a 15 min break at 4:00 pm.</p> -->

<!-- <h3>Audience</h3> -->

<p> Tutorial will be held at <a href="https://www.iscb.org/ismbeccb2021">ISMB/ECCB</a> conference on Friday, July 23 2021, 15:00 - 19:00 UTC.</p>

<p>The tutorial is designed for researchers who would like to learn the principles of machine learning techniques that can be applied when only a limited number of labeled data is available. The tutorial will require basic prior knowledge of fundamental concepts covered in introductory machine learning classes.
</p>

<A name="organizers"></A>
<h2>Presenters</h2>

<img src="img/maria_img.jpeg" align="left" hspace="10" width="120" vspace="2" height="120"/><p><a href="https://cs.stanford.edu/~mbrbic/">Maria Brbic</a>  is a postdoctoral fellow in Computer Science at Stanford University. Her research focuses on development of computational approaches that can generalize to never-before-seen contexts and tasks with particular interest in applications in single-cell genomics. She is involved in projects at Chan Zuckerberg Biohub and Stanford Neuro-omics Initiative. She received her Bachelor's degree from University of Zagreb, Croatia, and PhD degree in Computer Science with the best PhD thesis award from University of Zagreb. During her PhD she was also conducting research at University of Tokyo and Stanford University as a Fulbright Scholar. </p><br>

<img src="img/ChelseaFinn_hires.jpg" align="left" hspace="10" vspace="10" width="120" height="120"/><p><a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a> is an Assistant Professor of Computer Science and Electrical Engineering at Stanford University. Dr. Finn's research focuses on machine learning and robotics, with a significant focus on generalization and few-shot learning. She has pioneered work on meta-learning algorithms that can enable fast, few-shot adaptation, including the widely-used model-agnostic meta-learning algorithm.
Her PhD thesis, <i>Learning to Learn with Gradients</i>, received the ACM Doctoral Dissertation Award, and her research more broadly has been recognized by several other awards, including the Samsung AI Researcher of the Year, the Microsoft Research Faculty Fellowship, and the MIT Technology Review 35 under 35 Award. Her work has also been covered by various media outlets, including the New York Times, Wired, and Bloomberg. Finn received her Bachelor's degree in Electrical Engineering and Computer Science at MIT and her PhD in Computer Science at UC Berkeley.<br><br>
</p>

<img src="img/Jure-12_a-400x400.jpg" align="left" hspace="10" width="120" height="120"/><p><a href="https://cs.stanford.edu/people/jure/">Jure Leskovec</a> is Associate Professor of Computer Science at Stanford University, Chief Scientist at Pinterest, and investigator at Chan Zuckerberg Biohub. Dr. Leskovec was the co-founder of a machine learning startup Kosei, which was later acquired by Pinterest. His research focuses on machine learning and data mining large social, information, and biological networks. Computation over massive data is at the heart of his research and has applications in computer science, social sciences, marketing, and biomedicine. This research has won several awards including a Lagrange Prize, Microsoft Research Faculty Fellowship, the Alfred P. Sloan Fellowship, and numerous best paper and test of time awards. It has also been featured in popular press outlets such as the New York Times and the Wall Street Journal. Leskovec received his bachelor's degree in computer science from University of Ljubljana, Slovenia, PhD in machine learning from Carnegie Mellon University and postdoctoral training at Cornell University.
</p>

<br>
<br>

</div>
<!-- END: right column -->

<div id="footer">
<!-- you can put something here -->
</div>
</div>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-342639-4");
pageTracker._trackPageview();
} catch(err) {}</script>
</body>
</html>
